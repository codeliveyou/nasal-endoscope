{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ShTTr255UdU",
        "outputId": "e2d55e80-e4bf-4291-cc85-018992c0cda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/My Drive/nasal_endoscope_dataset.zip' -d '/content/data/'"
      ],
      "metadata": {
        "id": "l5I-0pB9EkMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required Libraries"
      ],
      "metadata": {
        "id": "w_luRSjrF2Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "hLEogBQA63gh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1H2wr1i695o",
        "outputId": "29ee9ee4-4452-409c-ce15-0d1da324ff1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "yKGbBtOJF9ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base directory containing 'in' and 'out' folders\n",
        "base_dir = '/content/data'\n",
        "\n",
        "# Image dimensions\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "tdTYDGsv7ACB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Normalize pixel values\n",
        "    validation_split=0.2,       # Use 20% of data for validation\n",
        "    rotation_range=40,          # Data augmentation parameters\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "lDsaiDUIEm39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'           # Set as training data\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'         # Set as validation data\n",
        ")"
      ],
      "metadata": {
        "id": "wwfEfsKDEo_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Model"
      ],
      "metadata": {
        "id": "_-iExpgHGExc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "    include_top=False,           # Exclude the top layers\n",
        "    weights='imagenet'           # Load weights pre-trained on ImageNet\n",
        ")"
      ],
      "metadata": {
        "id": "VWr1ANTrErwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "qy-1WkQlE5BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid')  # For binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "zo703QxSE6Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the Model"
      ],
      "metadata": {
        "id": "QLNdkgC0GMxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "AhrdaRyNE7yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model"
      ],
      "metadata": {
        "id": "vcWMMH6TGQm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "KWh5u8X4E-Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Model Performance"
      ],
      "metadata": {
        "id": "DgpZ6AdTGUiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vq-uGH40E_7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iEzsxslRFBZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning the Model"
      ],
      "metadata": {
        "id": "hHb-9YaMFFGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Let's unfreeze the last 50 layers\n",
        "fine_tune_at = len(base_model.layers) - 50\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "_I6nRsG6FDBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "lz3ISfoeFfpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = 5\n",
        "total_epochs = EPOCHS + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "YUCkCelFFgAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Download"
      ],
      "metadata": {
        "id": "ZnY76hMrFjI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('nasal_endoscope_classifier.h5')"
      ],
      "metadata": {
        "id": "lPulnqC3FmVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('nasal_endoscope_classifier.h5')"
      ],
      "metadata": {
        "id": "vKHP3xm3FoQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZV0KHoiFpdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploying the Model"
      ],
      "metadata": {
        "id": "C8FJ8P4EGinr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "BWIaTc8SGkJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model('nasal_endoscope_classifier.h5')"
      ],
      "metadata": {
        "id": "vvdxSJ9oGlkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Create batch dimension\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "QP3mTCO1Gmy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = 'path_to_your_image.jpg'\n",
        "img_array = preprocess_image(img_path)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Prediction: Outside the nasal cavity\")\n",
        "else:\n",
        "    print(\"Prediction: Inside the nasal cavity\")"
      ],
      "metadata": {
        "id": "-QLfpfMWGpXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing for CPU Inference"
      ],
      "metadata": {
        "id": "3TEeKT_TGuGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('nasal_endoscope_classifier.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "1Bp6mYAnGwHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"nasal_endoscope_classifier.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Prepare input data\n",
        "interpreter.set_tensor(input_details[0]['index'], img_array)\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the prediction\n",
        "prediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Prediction: Outside the nasal cavity\")\n",
        "else:\n",
        "    print(\"Prediction: Inside the nasal cavity\")"
      ],
      "metadata": {
        "id": "UPeWbG1wGxtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}